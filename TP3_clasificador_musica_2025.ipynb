{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1iLx2DRitxx"
   },
   "source": [
    "Universidad Torcuato Di Tella\n",
    "\n",
    "Licenciatura en Tecnolog√≠a Digital\\\n",
    "**Tecnolog√≠a Digital VI: Inteligencia Artificial**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25099,
     "status": "ok",
     "timestamp": 1729951536599,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "ZSdBL2673KUX",
    "outputId": "bba11036-c853-403f-9a59-644ee652a91b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchaudio in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (2.7.1)\n",
      "Requirement already satisfied: torch==2.7.1 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torchaudio) (2.7.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torch==2.7.1->torchaudio) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torch==2.7.1->torchaudio) (4.14.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torch==2.7.1->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torch==2.7.1->torchaudio) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torch==2.7.1->torchaudio) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from torch==2.7.1->torchaudio) (2025.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from sympy>=1.13.3->torch==2.7.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from jinja2->torch==2.7.1->torchaudio) (2.1.5)\n",
      "Requirement already satisfied: pydub in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (0.25.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: soundfile in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from soundfile) (1.17.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from soundfile) (1.24.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from cffi>=1.0->soundfile) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: wandb in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (8.2.1)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: packaging in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (23.2)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (6.31.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (2.11.7)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (2.30.0)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (1.3.6)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: typing-extensions<5,>=4.8 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from wandb) (4.14.0)\n",
      "\n",
      "Requirement already satisfied: colorama in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from pydantic<3->wandb) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from pydantic<3->wandb) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\laras\\miniconda3\\envs\\metodos\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchaudio\n",
    "%pip install  pydub\n",
    "%pip install soundfile\n",
    "%pip install wandb\n",
    "import wandb\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchaudio.datasets import GTZAN\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAR3tiGci2-e"
   },
   "source": [
    "\n",
    "# TP3: Encodeador de m√∫sica\n",
    "\n",
    "\n",
    "\n",
    "## Orden de pasos\n",
    "\n",
    "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
    "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
    "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
    "3. Visualizaci√≥n de los archivos\n",
    "4. Clasificaci√≥n\n",
    "5. Evaluaci√≥n\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt4FEe853KUX"
   },
   "outputs": [],
   "source": [
    "project_name='Music_genre_classification'\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.0005\n",
    "epochs = 50\n",
    "\n",
    "#Experimentos NN + waveform\n",
    "\n",
    "# experiment_name = 'Iden_1capa_densa'\n",
    "#experiment_name = 'Iden_3capas_NOdensa_1906_128_100'\n",
    "#experiment_name = 'Iden_3capas_NOdensa_1906_128_dropout'\n",
    "# experiment_name = 'Iden_3capas_densa_1906_128_dropout'\n",
    "# experiment_name = 'Iden_6capas_densa_sin_dropout'\n",
    "#experiment_name = 'Iden_6capas_NOdensa_sin_dropout'\n",
    "# experiment_name = 'Iden_6capas_NOdensa_dropout'\n",
    "# experiment_name = 'Iden_12capas_NOdensa_sindropout'\n",
    "# experiment_name = 'Iden_12capas_NOdensa_dropout04'\n",
    "# experiment_name = 'Iden_12capas_densa_dropout04'\n",
    "# experiment_name = 'Iden_12capas_densa_dropout08'\n",
    "\n",
    "# Experimentos CNN + espectrograma\n",
    "# experiment_name = 'CNN_2conv_1capa'\n",
    "experiment_name = 'CNN_2conv_5capas'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"larabarijhoff-universidad-torcuato-di-tella\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"tp3-td6-25\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    name = experiment_name\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_name == 'Iden_1capa_densa':\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(110250, 10), #primera capa oculta\n",
    ")\n",
    "    \n",
    "if experiment_name == 'Iden_3capas_NOdensa_1906_128_100':\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(110250, 50), #primera capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Linear(50, 40), #segunda capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Linear(40, 10)  # tercera capa\n",
    ")\n",
    "\n",
    "if experiment_name == 'Iden_3capas_NOdensa_1906_128_100':\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(110250, 50), #primera capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Linear(50, 40), #segunda capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Linear(40, 10)  # tercera capa\n",
    ")\n",
    "\n",
    "if experiment_name == 'Iden_3capas_NOdensa_1906_128_dropout':\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(110250, 50), #primera capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(50, 40), #segunda capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(40, 10)  # tercera capa\n",
    ")\n",
    "\n",
    "if experiment_name == 'Iden_3capas_densa_1906_128_dropout':\n",
    "    model = nn.Sequential(\n",
    "    nn.Linear(110250, 1024), #primera capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(1024, 512), #segunda capa oculta\n",
    "    nn.Identity(),\n",
    "    nn.Dropout(0.8),\n",
    "    nn.Linear(512, 10)  # tercera capa\n",
    ")\n",
    "    \n",
    "if experiment_name == 'Iden_6capas_densa_sin_dropout':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 1024),\n",
    "        nn.Identity(),\n",
    "        nn.Linear(1024, 512),\n",
    "        nn.Identity(),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.Identity(),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.Identity(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.Identity(),\n",
    "        nn.Linear(64, 10)\n",
    ")\n",
    "if experiment_name == 'Iden_6capas_NOdensa_sindropout':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 50), nn.Identity(),\n",
    "        nn.Linear(50, 45), nn.Identity(),\n",
    "        nn.Linear(45, 40), nn.Identity(),\n",
    "        nn.Linear(40, 35), nn.Identity(),\n",
    "        nn.Linear(35, 30), nn.Identity(),\n",
    "        nn.Linear(30, 10)\n",
    ")\n",
    "if experiment_name == 'Iden_6capas_NOdensa_dropout':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 50), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(50, 45), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(45, 40), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(40, 35), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(35, 30), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(30, 10)\n",
    "    )\n",
    "\n",
    "if experiment_name == 'Iden_12capas_NOdensa_sindropout':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 60), nn.Identity(),\n",
    "        nn.Linear(60, 55), nn.Identity(),\n",
    "        nn.Linear(55, 50), nn.Identity(),\n",
    "        nn.Linear(50, 45), nn.Identity(),\n",
    "        nn.Linear(45, 40), nn.Identity(),\n",
    "        nn.Linear(40, 35), nn.Identity(),\n",
    "        nn.Linear(35, 30), nn.Identity(),\n",
    "        nn.Linear(30, 25), nn.Identity(),\n",
    "        nn.Linear(25, 20), nn.Identity(),\n",
    "        nn.Linear(20, 15), nn.Identity(),\n",
    "        nn.Linear(15, 12), nn.Identity(),\n",
    "        nn.Linear(12, 10)\n",
    ")\n",
    "\n",
    "if experiment_name == 'Iden_12capas_NOdensa_dropout04':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 60), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(60, 55), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(55, 50), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(50, 45), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(45, 40), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(40, 35), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(35, 30), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(30, 25), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(25, 20), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(20, 15), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(15, 12), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(12, 10)\n",
    ")\n",
    "if experiment_name == 'Iden_12capas_densa_dropout04':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 2048), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(2048, 1024), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(1024, 1024), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(1024, 512), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(512, 512), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(512, 256), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(256, 256), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(256, 128), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(128, 128), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(128, 64), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(64, 32), nn.Identity(), nn.Dropout(0.4),\n",
    "        nn.Linear(32, 10)\n",
    ")\n",
    "if experiment_name == 'Iden_12capas_densa_dropout08':\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(110250, 2048), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(2048, 1024), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(1024, 1024), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(1024, 512), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(512, 512), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(512, 256), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(256, 256), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(256, 128), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(128, 128), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(128, 64), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(64, 32), nn.Identity(), nn.Dropout(0.8),\n",
    "        nn.Linear(32, 10)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimentos CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if experiment_name == 'CNN_2conv_1capa':\n",
    "    model = nn.Sequential(\n",
    "    # Primera capa convolucional\n",
    "    nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),  # Conv2D\n",
    "    nn.Identity(),                                                                 # Identity\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),                                         # MaxPool2D\n",
    "\n",
    "    # Segunda capa convolucional\n",
    "    nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1), # Conv2D\n",
    "    nn.Identity(),                                                                  # Identity\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),                                          # MaxPool2D\n",
    "\n",
    "    # Capa totalmente conectada para la clasificaci√≥n\n",
    "    nn.Flatten(),                                                                   # Aplanar la salida\n",
    "    nn.Linear(int(64 * (201 // 4) * (552 // 4)), 10),                                 # Capa densa\n",
    "    nn.Identity()                                                                   # Identity\n",
    ")\n",
    "    \n",
    "if experiment_name == 'CNN_2conv_5capas':\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        \n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "        \n",
    "        nn.Linear(64 * (201 // 4) * (552 // 4), 512),\n",
    "        nn.Linear(512, 256),\n",
    "        nn.Linear(256, 128),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.Linear(64, 10)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU5G8mTE-5zM"
   },
   "source": [
    "### 2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYLOe3isiV0b"
   },
   "source": [
    "data_dir es el path donde pusimos la carpeta genres. \"'//content/drive/MyDrive/Materias/TD6 - Inteligencia Artificial/TPs/2023/TP4/genres/'\" es un ejemplo. Modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2533,
     "status": "ok",
     "timestamp": 1729951706742,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "7kYMlPdYrzCi",
    "outputId": "e6d02c55-d252-44f1-9e63-f20f8a1c6f68"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir=\"..\\genres_5sec\" #para lari\n",
    "#data_dir=\"../genres_5sec\" #para piki\n",
    "list_files=os.listdir(data_dir)\n",
    "classes=[]\n",
    "for file in list_files:\n",
    "  name='{}/{}'.format(data_dir,file)\n",
    "  if os.path.isdir(name):\n",
    "    classes.append(file)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJxZV04XZtnP"
   },
   "outputs": [],
   "source": [
    "samplerate=22050\n",
    "def parse_genres(fname):\n",
    "    parts = fname.split('/')[-1].split('.')[0]\n",
    "    return parts #' '.join(parts[0])\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.files =[]\n",
    "        for c in classes:\n",
    "          self.files = self.files + [fname for fname in os.listdir(os.path.join(root,c)) if fname.endswith('.wav')]\n",
    "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
    "        #self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        fname = self.files[i]\n",
    "\n",
    "        #img = self.transform(open_image(fpath))\n",
    "        genre = parse_genres(fname)\n",
    "        fpath = os.path.join(self.root,genre, fname)\n",
    "        class_idx = self.classes.index(genre)\n",
    "        audio = torchaudio.load(fpath)[0]\n",
    "\n",
    "        return audio, class_idx\n",
    "dataset = MusicDataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDBqRCWT0p8j"
   },
   "source": [
    "### 3. Visualizaci√≥n de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proba cargar un archivo v√°lido lara\n",
    "waveform, sr = torchaudio.load(r'..\\genres_5sec\\blues\\blues.00000.wav') #para lari\n",
    "#waveform, sr = torchaudio.load(r'../genres_5sec/blues/blues.00000.wav') #para piki\n",
    "print(waveform.shape, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1729951714981,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "PiDa813SG-2f",
    "outputId": "4a189e17-7eda-4c58-bdd2-6a0baae9bdf3"
   },
   "outputs": [],
   "source": [
    "waveform,label= dataset[0]\n",
    "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 2051,
     "status": "ok",
     "timestamp": 1729951717030,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "_MA3RlaDG-0A",
    "outputId": "59c3f5c0-b565-4c79-d315-a653de951c05"
   },
   "outputs": [],
   "source": [
    "specgram=tt.Spectrogram()(waveform)\n",
    "print(\"shape of spectogram {}\".format(specgram.size()))\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(specgram.log2()[0,:,:].numpy(),cmap='magma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHdITZUAzQYG"
   },
   "outputs": [],
   "source": [
    "print(\"Waveform: {}\\n\".format(waveform))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(waveform.t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEFLn0DAK4Y4"
   },
   "source": [
    "Escuchamos el espectograma con la librer√≠a de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "kLwAcRJ155pl",
    "outputId": "71e85a3f-0319-419a-aa04-fb3cc208a505"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(waveform,rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "vcCdQJS8G-pX",
    "outputId": "98d76ed6-89b5-4992-83fc-b6f9d57c65c4"
   },
   "outputs": [],
   "source": [
    "specgram.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "-dr5Qhgk5sjL",
    "outputId": "dcaafe9a-2223-43e0-c4d6-267dd76a710d"
   },
   "outputs": [],
   "source": [
    "# Fijar la semilla para que la divisi√≥n sea reproducible\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Calcular tama√±os basados en porcentajes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Dividir el dataset\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Comprobaci√≥n de los tama√±os de cada subconjunto\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "wBHjbBoo5sG1",
    "outputId": "38c86cce-ddd8-4041-82ff-355b97c90397"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, pin_memory=True)\n",
    "# Prueba para verificar si el DataLoader de entrenamiento funciona correctamente\n",
    "try:\n",
    "    for data, labels in train_dl:\n",
    "        print(\"Forma de los datos:\", data.shape)\n",
    "        print(\"Etiquetas:\", labels)\n",
    "        break  # Carga solo el primer batch\n",
    "except Exception as e:\n",
    "    print(\"Error al cargar los datos del train_dl:\", e)\n",
    "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=0, pin_memory=True)\n",
    "test_dl = DataLoader(test_ds,1, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXnHDpoYttX8"
   },
   "source": [
    "### 4. Clasificaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkfBRO910vu3"
   },
   "outputs": [],
   "source": [
    "# dada por ellos:\n",
    "\n",
    "# #1 Capa densa\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input, hidden_dim=64, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         # Define layers dynamically\n",
    "#         self.fc1 = nn.Linear(n_input, n_output)  # First hidden layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#        x = self.fc1(x)\n",
    "#        return x\n",
    "    \n",
    "#3 Capas NO Densas\n",
    "#La de mejor resultado dentro de NN en cuanto a cantidad de capas y densidad\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input, hidden_dim=64, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         # Define layers dynamically\n",
    "#         self.fc1 = nn.Linear(n_input, 50)  # First hidden layer\n",
    "#         self.fc2 = nn.Linear(50, 40)  # Second hidden layer\n",
    "#         self.fc3 = nn.Linear(40, n_output)  # Third hidden layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "#3 Capas NO Densas con Dropout\n",
    "#La de mejor resultado dentro de NN en cuanto a cantidad de capas y densidad\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input, hidden_dim=64, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         # Define layers dynamically\n",
    "#         self.fc1 = nn.Linear(n_input, 50)  # First hidden layer\n",
    "#         self.fc2 = nn.Linear(50, 40)  # Second hidden layer\n",
    "#         self.fc3 = nn.Linear(40, n_output)  # Third hidden layer\n",
    "#         self.dropout = nn.Dropout(p=0.8)  # Dropout layer with probability p\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.dropout(x)        # Dropout\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.dropout(x)        # Dropout\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# #3 Capas Densas con Dropout\n",
    "# #La de mejor resultado dentro de NN en cuanto a cantidad de capas y densidad\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input, hidden_dim=64, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         # Define layers dynamically\n",
    "#         self.fc1 = nn.Linear(n_input, 2048)  # First hidden layer\n",
    "#         self.fc2 = nn.Linear(2048, 1024)  # Second hidden layer\n",
    "#         self.fc3 = nn.Linear(1024, n_output)  # Third hidden layer\n",
    "#         self.dropout = nn.Dropout(p=0.8)  # Dropout layer with probability p\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.dropout(x)        # Dropout\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.dropout(x)        # Dropout\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "# 6 Capas Densas sin Dropout\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 1024)\n",
    "#         self.fc2 = nn.Linear(1024, 512)\n",
    "#         self.fc3 = nn.Linear(512, 256)\n",
    "#         self.fc4 = nn.Linear(256, 128)\n",
    "#         self.fc5 = nn.Linear(128, 64)\n",
    "#         self.fc6 = nn.Linear(64, n_output)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.fc5(x)\n",
    "#         x = self.fc6(x)\n",
    "#         return x\n",
    "\n",
    "# #6 Capas no Densas sin Dropout\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input=110250, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 50)\n",
    "#         self.fc2 = nn.Linear(50, 45)\n",
    "#         self.fc3 = nn.Linear(45, 40)\n",
    "#         self.fc4 = nn.Linear(40, 35)\n",
    "#         self.fc5 = nn.Linear(35, 30)\n",
    "#         self.fc6 = nn.Linear(30, n_output)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.fc5(x)\n",
    "#         x = self.fc6(x)\n",
    "#         return x\n",
    "\n",
    "# #6 Capas no Densas con Dropout\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input=110250, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 50)\n",
    "#         self.fc2 = nn.Linear(50, 45)\n",
    "#         self.fc3 = nn.Linear(45, 40)\n",
    "#         self.fc4 = nn.Linear(40, 35)\n",
    "#         self.fc5 = nn.Linear(35, 30)\n",
    "#         self.fc6 = nn.Linear(30, n_output)\n",
    "#         self.dropout = nn.Dropout(0.8)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(self.fc1(x))\n",
    "#         x = self.dropout(self.fc2(x))\n",
    "#         x = self.dropout(self.fc3(x))\n",
    "#         x = self.dropout(self.fc4(x))\n",
    "#         x = self.dropout(self.fc5(x))\n",
    "#         x = self.fc6(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# 12 Capas no Densas sin Dropout\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input=110250, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 60)\n",
    "#         self.fc2 = nn.Linear(60, 55)\n",
    "#         self.fc3 = nn.Linear(55, 50)\n",
    "#         self.fc4 = nn.Linear(50, 45)\n",
    "#         self.fc5 = nn.Linear(45, 40)\n",
    "#         self.fc6 = nn.Linear(40, 35)\n",
    "#         self.fc7 = nn.Linear(35, 30)\n",
    "#         self.fc8 = nn.Linear(30, 25)\n",
    "#         self.fc9 = nn.Linear(25, 20)\n",
    "#         self.fc10 = nn.Linear(20, 15)\n",
    "#         self.fc11 = nn.Linear(15, 12)\n",
    "#         self.fc12 = nn.Linear(12, n_output)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.fc4(x)\n",
    "#         x = self.fc5(x)\n",
    "#         x = self.fc6(x)\n",
    "#         x = self.fc7(x)\n",
    "#         x = self.fc8(x)\n",
    "#         x = self.fc9(x)\n",
    "#         x = self.fc10(x)\n",
    "#         x = self.fc11(x)\n",
    "#         x = self.fc12(x)\n",
    "#         return x\n",
    "\n",
    "# # 12 Capas no Densas con Dropout\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input=110250, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 60)\n",
    "#         self.fc2 = nn.Linear(60, 55)\n",
    "#         self.fc3 = nn.Linear(55, 50)\n",
    "#         self.fc4 = nn.Linear(50, 45)\n",
    "#         self.fc5 = nn.Linear(45, 40)\n",
    "#         self.fc6 = nn.Linear(40, 35)\n",
    "#         self.fc7 = nn.Linear(35, 30)\n",
    "#         self.fc8 = nn.Linear(30, 25)\n",
    "#         self.fc9 = nn.Linear(25, 20)\n",
    "#         self.fc10 = nn.Linear(20, 15)\n",
    "#         self.fc11 = nn.Linear(15, 12)\n",
    "#         self.fc12 = nn.Linear(12, n_output)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(self.fc1(x))\n",
    "#         x = self.dropout(self.fc2(x))\n",
    "#         x = self.dropout(self.fc3(x))\n",
    "#         x = self.dropout(self.fc4(x))\n",
    "#         x = self.dropout(self.fc5(x))\n",
    "#         x = self.dropout(self.fc6(x))\n",
    "#         x = self.dropout(self.fc7(x))\n",
    "#         x = self.dropout(self.fc8(x))\n",
    "#         x = self.dropout(self.fc9(x))\n",
    "#         x = self.dropout(self.fc10(x))\n",
    "#         x = self.dropout(self.fc11(x))\n",
    "#         x = self.fc12(x)\n",
    "#         return x\n",
    "\n",
    "# # 12 Capas Densas con Dropout 0.4\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input=110250, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 2048)\n",
    "#         self.fc2 = nn.Linear(2048, 1024)\n",
    "#         self.fc3 = nn.Linear(1024, 1024)\n",
    "#         self.fc4 = nn.Linear(1024, 512)\n",
    "#         self.fc5 = nn.Linear(512, 512)\n",
    "#         self.fc6 = nn.Linear(512, 256)\n",
    "#         self.fc7 = nn.Linear(256, 256)\n",
    "#         self.fc8 = nn.Linear(256, 128)\n",
    "#         self.fc9 = nn.Linear(128, 128)\n",
    "#         self.fc10 = nn.Linear(128, 64)\n",
    "#         self.fc11 = nn.Linear(64, 32)\n",
    "#         self.fc12 = nn.Linear(32, n_output)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(self.fc1(x))\n",
    "#         x = self.dropout(self.fc2(x))\n",
    "#         x = self.dropout(self.fc3(x))\n",
    "#         x = self.dropout(self.fc4(x))\n",
    "#         x = self.dropout(self.fc5(x))\n",
    "#         x = self.dropout(self.fc6(x))\n",
    "#         x = self.dropout(self.fc7(x))\n",
    "#         x = self.dropout(self.fc8(x))\n",
    "#         x = self.dropout(self.fc9(x))\n",
    "#         x = self.dropout(self.fc10(x))\n",
    "#         x = self.dropout(self.fc11(x))\n",
    "#         x = self.fc12(x)\n",
    "#         return x\n",
    "\n",
    "# #12 capas densas dropout 0.8\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input=110250, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         self.fc1 = nn.Linear(n_input, 2048)\n",
    "#         self.fc2 = nn.Linear(2048, 1024)\n",
    "#         self.fc3 = nn.Linear(1024, 1024)\n",
    "#         self.fc4 = nn.Linear(1024, 512)\n",
    "#         self.fc5 = nn.Linear(512, 512)\n",
    "#         self.fc6 = nn.Linear(512, 256)\n",
    "#         self.fc7 = nn.Linear(256, 256)\n",
    "#         self.fc8 = nn.Linear(256, 128)\n",
    "#         self.fc9 = nn.Linear(128, 128)\n",
    "#         self.fc10 = nn.Linear(128, 64)\n",
    "#         self.fc11 = nn.Linear(64, 32)\n",
    "#         self.fc12 = nn.Linear(32, n_output)\n",
    "#         self.dropout = nn.Dropout(0.8)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.dropout(self.fc1(x))\n",
    "#         x = self.dropout(self.fc2(x))\n",
    "#         x = self.dropout(self.fc3(x))\n",
    "#         x = self.dropout(self.fc4(x))\n",
    "#         x = self.dropout(self.fc5(x))\n",
    "#         x = self.dropout(self.fc6(x))\n",
    "#         x = self.dropout(self.fc7(x))\n",
    "#         x = self.dropout(self.fc8(x))\n",
    "#         x = self.dropout(self.fc9(x))\n",
    "#         x = self.dropout(self.fc10(x))\n",
    "#         x = self.dropout(self.fc11(x))\n",
    "#         x = self.fc12(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arquitecura CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #2 convoluciones y 1 capa densa\n",
    "# class CNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(in_channels = 1,   # 1 canal de entrada.\n",
    "#                                out_channels = 32, # 32 canales de salida.\n",
    "#                                kernel_size = 3,   # Kernel 3x3.\n",
    "#                                stride = 1,        # Pasos de 1.\n",
    "#                                padding = 1)       # Padding de 1 para mantener el tama√±o.\n",
    "#         self.conv2 = nn.Conv2d(32, 64,\n",
    "#                                kernel_size = 3, stride = 1, padding = 1)\n",
    "#         self.fc1 = nn.Linear((64 * (201//4)) * (552//4),\n",
    "#                              # 201 es el alto del espectograma y 552 ancho\n",
    "#                              # convolucional se le aplica un maxpool de 2x2.\n",
    "#                              10)\n",
    "\n",
    "#     #dividido 2 por max pool o promedio\n",
    "#     def forward(self, x):\n",
    "#         x = nn.Identity()(self.conv1(x))\n",
    "#         x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
    "#         x = nn.Identity()(self.conv2(x))\n",
    "#         x = nn.MaxPool2d(kernel_size = 2, stride = 2)(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = nn.Identity()(self.fc1(x))\n",
    "#         return x\n",
    "\n",
    "# 2 convoluciones y 5 capas densa\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # üîπ Convoluciones\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64,\n",
    "                               kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # üîπ Tama√±o del espectrograma de entrada: [1, 1, 201, 552]\n",
    "        # Dos maxpools reducen altura y ancho a la mitad dos veces ‚Üí 201 ‚Üí 100, 552 ‚Üí 276\n",
    "        flattened_size = 64 * (201 // 4) * (552 // 4)  # = 64 * 50 * 138\n",
    "\n",
    "        # üîπ Capas densas (sin activaci√≥n)\n",
    "        self.fc1 = nn.Linear(flattened_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)  # 10 g√©neros\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "Ryss1Hhm3KUf",
    "outputId": "33618575-44a9-4a2f-eb82-f477f7d0f22e"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else\n",
    "                      'mps' if torch.backends.mps.is_available() else\n",
    "                      'cpu')\n",
    "\n",
    "# model = MLP(n_input=110250, n_output=len(classes))\n",
    "# model.to(device)\n",
    "# print(model)\n",
    "\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "# n = count_parameters(model)\n",
    "# print(\"Number of parameters: %s\" % n)\n",
    "\n",
    "#Para imprimir el modelo con CNN\n",
    "# input_shape = (1, 201, 552)\n",
    "# model = CNN(input_shape)\n",
    "model = CNN()\n",
    "model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "jTnjUZU_3oou",
    "outputId": "8a3e4f17-5425-4e30-dc13-14c724ac6971"
   },
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr= learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y Validation para Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6cJrYPk8V8J",
    "outputId": "a184e038-e1e1-41bc-a7d4-92c22a46eddd"
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "# valid_losses = []\n",
    "# num_epochs = epochs\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect() #importante para ir liberando memoria ram\n",
    "\n",
    "# best_valid_accuracy = 0\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     losses = []\n",
    "\n",
    "#     # Train\n",
    "#     model.train()\n",
    "#     for wav, genre_index in train_dl:\n",
    "#         optimizer.zero_grad()  # Clear gradients\n",
    "#         wav=wav.to(device)\n",
    "#         genre_index =torch.as_tensor(genre_index).to(device)\n",
    "\n",
    "#         # Forward\n",
    "#         out = model(wav)\n",
    "#         #M5\n",
    "#         loss = loss_function(out.squeeze(), genre_index)\n",
    "\n",
    "#         # Backward\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         losses.append(loss.item())\n",
    "\n",
    "#         del wav #importante para ir liberando memoria ram\n",
    "#         del genre_index #importante para ir liberando memoria ram\n",
    "#         del loss #importante para ir liberando memoria ram\n",
    "#         del out  #importante para ir liberando memoria ram\n",
    "#         torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
    "#         gc.collect() #importante para ir liberando memoria ram\n",
    "#         wandb.log({'train_loss': np.mean(losses)}, commit = False)\n",
    "\n",
    "#     print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n",
    "\n",
    "#     # Validation\n",
    "#     model.eval()\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     losses = []\n",
    "#     correct =0\n",
    "#     for wav, genre_index in valid_dl:\n",
    "#         #print(wav, genre, index)\n",
    "#         wav = wav.to(device)\n",
    "#         genre_index = genre_index.to(device)\n",
    "\n",
    "#         out = model(wav)\n",
    "\n",
    "#         loss = loss_function(out.squeeze() , genre_index)\n",
    "\n",
    "#         losses.append(loss.item())\n",
    "#         #M5\n",
    "#         pred= out.argmax(dim=-1).flatten()\n",
    "#         # append labels and predictions\n",
    "#         correct += pred.eq(genre_index).sum().item()\n",
    "#         y_true.extend(genre_index)\n",
    "#         y_pred.extend(pred)\n",
    "#         del wav #importante para ir liberando memoria ram\n",
    "#         del genre_index #importante para ir liberando memoria ram\n",
    "#         del loss #importante para ir liberando memoria ram\n",
    "#         del out  #importante para ir liberando memoria ram\n",
    "#         torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
    "#         gc.collect() #importante para ir liberando memoria ram\n",
    "\n",
    "#     valid_accuracy =correct/ len(valid_dl.dataset)\n",
    "#     valid_loss = np.mean(losses)\n",
    "#     print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, valid_accuracy))\n",
    "\n",
    "#     # Guardar el mejor modelo seg√∫n la precisi√≥n de validaci√≥n\n",
    "#     if valid_accuracy > best_valid_accuracy:\n",
    "#         best_valid_accuracy = valid_accuracy\n",
    "#         torch.save(model.state_dict(), 'best_model.ckpt')\n",
    "\n",
    "#     wandb.log({\n",
    "#         'val_loss': valid_loss,         # P√©rdida de validaci√≥n calculada arriba\n",
    "#         'val_accuracy': valid_accuracy        # Exactitud de validaci√≥n calculada arriba\n",
    "#         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train y validation con Espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "valid_losses = []\n",
    "num_epochs = epochs\n",
    "delay_epochs = 5\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() #importante para ir liberando memoria ram\n",
    "\n",
    "best_valid_accuracy = 0\n",
    "\n",
    "# Definir el tipo de regularizaci√≥n (None, 'L1', o 'L2')\n",
    "#regularization_type = 'L2'\n",
    "#lambda_reg = 1e-4\n",
    "#lambda_reg = 1e-6\n",
    "#lambda_red = 1e-3\n",
    "#Esta comentado pues no se usa regularizacion\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for wav, genre_index in train_dl:\n",
    "        optimizer.zero_grad()\n",
    "        wav=wav.to(device)\n",
    "        genre_index =torch.as_tensor(genre_index).to(device)\n",
    "\n",
    "        specgram = tt.Spectrogram().to(device)\n",
    "        specgram_wav = specgram(wav)\n",
    "\n",
    "        # Forward\n",
    "        out = model(specgram_wav)\n",
    "\n",
    "        loss = loss_function(out.squeeze(), genre_index)\n",
    "\n",
    "\n",
    "         #Regularizaci√≥n L1 o  L2\n",
    "        #if regularization_type == 'L1':\n",
    "            #l1_reg = torch.tensor(0., device=device)\n",
    "            #for param in model.parameters():\n",
    "                #l1_reg += torch.norm(param, 1)  # Norma L1\n",
    "            #loss += lambda_reg * l1_reg  # Agregar L1 a la p√©rdida total\n",
    "        #elif regularization_type == 'L2':\n",
    "            #l2_reg = torch.tensor(0., device=device)\n",
    "            #for param in model.parameters():\n",
    "                #l2_reg += torch.norm(param, 2)  # Norma L2\n",
    "            #loss += lambda_reg * l2_reg  # Agregar L2 a la p√©rdida total\n",
    "\n",
    "            #Comentado por no se usa regularizacion\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        del wav\n",
    "        del genre_index\n",
    "        del loss\n",
    "        del out\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    losses = []\n",
    "    correct =0\n",
    "    for wav, genre_index in valid_dl:\n",
    "        wav = wav.to(device)\n",
    "        genre_index = genre_index.to(device)\n",
    "\n",
    "        specgram = tt.Spectrogram().to(device)\n",
    "        specgram_wav = specgram(wav)\n",
    "\n",
    "        out = model(specgram_wav)\n",
    "\n",
    "        loss = loss_function(out.squeeze(), genre_index)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        pred= out.argmax(dim=-1).flatten()\n",
    "\n",
    "        correct += pred.eq(genre_index).sum().item()\n",
    "        y_true.extend(genre_index)\n",
    "        y_pred.extend(pred)\n",
    "        del wav\n",
    "        del genre_index\n",
    "        del loss\n",
    "        del out\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "    valid_accuracy =correct/ len(valid_dl.dataset)\n",
    "    valid_loss = np.mean(losses)\n",
    "    print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, valid_accuracy))\n",
    "\n",
    "\n",
    "    # Guardar el mejor modelo seg√∫n la precisi√≥n de validaci√≥n\n",
    "    if valid_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = valid_accuracy\n",
    "        torch.save(model.state_dict(), 'best_model.ckpt')\n",
    "\n",
    "    #Comentado pues no se utiliza en el mejor modelo\n",
    "\n",
    "    # LR no fijos\n",
    "    #Decaimiento exponencial\n",
    "    #if epoch >= delay_epochs: #con if es decaimiento exponencial retrasado\n",
    "    #scheduler.step()\n",
    "    #current_lr = scheduler.get_last_lr()[0]\n",
    "    #print(f\"Learning Rate despu√©s de la epoch {epoch+1}: {current_lr}\")\n",
    "    #Decaimiento basado en error\n",
    "    #scheduler.step(valid_loss)\n",
    "    #current_lr = scheduler.get_last_lr()[0]\n",
    "    #print(f\"Learning Rate despu√©s de la epoch {epoch+1}: {current_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFwYdlWxCN0M"
   },
   "source": [
    "\n",
    "\n",
    "### 5. Evaluaci√≥n\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6RFD17nU81b"
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds,1,shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test para Waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Pqtx-D0zAwa"
   },
   "outputs": [],
   "source": [
    "# # Load the best model\n",
    "# S = torch.load('best_model.ckpt')\n",
    "# model.load_state_dict(S)\n",
    "# print('loaded!')\n",
    "\n",
    "# # Run evaluation\n",
    "# model.eval()\n",
    "# y_true = []\n",
    "# y_pred = []\n",
    "# correct = 0\n",
    "# with torch.no_grad():\n",
    "#     for wav, genre_index in test_dl:\n",
    "#         wav = wav.to(device)\n",
    "#         genre_index = genre_index.to(device)\n",
    "\n",
    "#         out = model(wav)\n",
    "\n",
    "#         pred= out.argmax(dim=-1).flatten()\n",
    "#         # append labels and predictions\n",
    "#         correct += pred.eq(genre_index).sum().item()\n",
    "#         y_true.extend(genre_index)\n",
    "#         y_pred.extend(pred)\n",
    "\n",
    "# test_accuracy = correct/ len(test_dl.dataset)\n",
    "# print('Epoch: [%d/%d], Test accuracy: %.4f' % (epoch+1, num_epochs, test_accuracy))\n",
    "\n",
    "# # Registrar la precisi√≥n y la p√©rdida en W&B\n",
    "# wandb.summary[\"test_accuracy\"]= test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test para Espectrograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "S = torch.load('best_model.ckpt')\n",
    "model.load_state_dict(S)\n",
    "print('loaded!')\n",
    "\n",
    "# Run evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "correct = 0\n",
    "with torch.no_grad(): #desactiva calculo de gradientes\n",
    "    for wav, genre_index in test_dl:\n",
    "        wav = wav.to(device)\n",
    "        genre_index = genre_index.to(device)\n",
    "\n",
    "        specgram = tt.Spectrogram().to(device)\n",
    "        specgram_wav = specgram(wav)\n",
    "\n",
    "        out = model(specgram_wav)\n",
    "\n",
    "        pred= out.argmax(dim=-1).flatten()\n",
    "        # append labels and predictions\n",
    "        correct += pred.eq(genre_index).sum().item()\n",
    "        y_true.extend(genre_index)\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "test_accuracy = correct/ len(test_dl.dataset)\n",
    "print('Epoch: [%d/%d], Test accuracy: %.4f' % (epoch+1, num_epochs, test_accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the run and upload any remaining data.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GA6O4xauAZFH"
   },
   "outputs": [],
   "source": [
    "waveform,label= test_dl.dataset[12]\n",
    "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUg9zOkbAo6-"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(waveform, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnqTp_twAtH7"
   },
   "outputs": [],
   "source": [
    "wav= torch.unsqueeze(waveform, dim=0)\n",
    "model.to(device)\n",
    "wav =wav.to(device)\n",
    "out = model(specgram_wav) #cambiar a wav para waveform\n",
    "pred= out.argmax(dim=-1).flatten()\n",
    "classes[pred], classes[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_accuracy)\n",
    "print(valid_accuracy)\n",
    "print(valid_loss)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1uSkwnShxrUa6Ocl0ZCQzQeuwKQWp24Z5",
     "timestamp": 1729951799904
    },
    {
     "file_id": "1lrf3m7jiHExmejRfEvvkQ_-QhvS9yGXB",
     "timestamp": 1699196272732
    },
    {
     "file_id": "1MM5mye38mQC3MsJVPhger99FhS0t8g7u",
     "timestamp": 1699191135065
    },
    {
     "file_id": "1-ubJpQ2KKjHbD0Bw5Vk6hNK1jK4EP8Vr",
     "timestamp": 1699127564522
    }
   ]
  },
  "kernelspec": {
   "display_name": "metodos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
