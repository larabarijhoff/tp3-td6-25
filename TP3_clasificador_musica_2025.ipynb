{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1iLx2DRitxx"
   },
   "source": [
    "Universidad Torcuato Di Tella\n",
    "\n",
    "Licenciatura en Tecnología Digital\\\n",
    "**Tecnología Digital VI: Inteligencia Artificial**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25099,
     "status": "ok",
     "timestamp": 1729951536599,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "ZSdBL2673KUX",
    "outputId": "bba11036-c853-403f-9a59-644ee652a91b"
   },
   "outputs": [],
   "source": [
    "%pip install torchaudio\n",
    "%pip install  pydub\n",
    "%pip install soundfile\n",
    "%pip install wandb\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import tarfile\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torchaudio.datasets import GTZAN\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio.transforms as tt\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import wandb\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lAR3tiGci2-e"
   },
   "source": [
    "\n",
    "# TP3: Encodeador de música\n",
    "\n",
    "\n",
    "\n",
    "## Orden de pasos\n",
    "\n",
    "0. Elijan GPU para que corra mas rapido (RAM --> change runtime type --> T4 GPU)\n",
    "1. Descargamos el dataset y lo descomprimimos en alguna carpeta en nuestro drive.\n",
    "2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
    "3. Visualización de los archivos\n",
    "4. Clasificación\n",
    "5. Evaluación\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rt4FEe853KUX"
   },
   "outputs": [],
   "source": [
    "project_name='Music_genre_classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oU5G8mTE-5zM"
   },
   "source": [
    "### 2. Conectamos la notebook a gdrive y seteamos data_dir con el path a los archivos.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qYLOe3isiV0b"
   },
   "source": [
    "data_dir es el path donde pusimos la carpeta genres. \"'//content/drive/MyDrive/Materias/TD6 - Inteligencia Artificial/TPs/2023/TP4/genres/'\" es un ejemplo. Modificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2533,
     "status": "ok",
     "timestamp": 1729951706742,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "7kYMlPdYrzCi",
    "outputId": "e6d02c55-d252-44f1-9e63-f20f8a1c6f68"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir=\"..\\genres_5sec\"\n",
    "list_files=os.listdir(data_dir)\n",
    "classes=[]\n",
    "for file in list_files:\n",
    "  name='{}/{}'.format(data_dir,file)\n",
    "  if os.path.isdir(name):\n",
    "    classes.append(file)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GJxZV04XZtnP"
   },
   "outputs": [],
   "source": [
    "samplerate=22050\n",
    "def parse_genres(fname):\n",
    "    parts = fname.split('/')[-1].split('.')[0]\n",
    "    return parts #' '.join(parts[0])\n",
    "\n",
    "class MusicDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        super().__init__()\n",
    "        self.root = root\n",
    "        self.files =[]\n",
    "        for c in classes:\n",
    "          self.files = self.files + [fname for fname in os.listdir(os.path.join(root,c)) if fname.endswith('.wav')]\n",
    "        self.classes = list(set(parse_genres(fname) for fname in self.files))\n",
    "        #self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        fname = self.files[i]\n",
    "\n",
    "        #img = self.transform(open_image(fpath))\n",
    "        genre = parse_genres(fname)\n",
    "        fpath = os.path.join(self.root,genre, fname)\n",
    "        class_idx = self.classes.index(genre)\n",
    "        audio = torchaudio.load(fpath)[0]\n",
    "\n",
    "        return audio, class_idx\n",
    "dataset = MusicDataset(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDBqRCWT0p8j"
   },
   "source": [
    "### 3. Visualización de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proba cargar un archivo válido lara\n",
    "waveform, sr = torchaudio.load(r'..\\genres_5sec\\blues\\blues.00000.wav')\n",
    "print(waveform.shape, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1729951714981,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "PiDa813SG-2f",
    "outputId": "4a189e17-7eda-4c58-bdd2-6a0baae9bdf3"
   },
   "outputs": [],
   "source": [
    "waveform,label= dataset[0]\n",
    "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "executionInfo": {
     "elapsed": 2051,
     "status": "ok",
     "timestamp": 1729951717030,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "_MA3RlaDG-0A",
    "outputId": "59c3f5c0-b565-4c79-d315-a653de951c05"
   },
   "outputs": [],
   "source": [
    "specgram=tt.Spectrogram()(waveform)\n",
    "print(\"shape of spectogram {}\".format(specgram.size()))\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.imshow(specgram.log2()[0,:,:].numpy(),cmap='magma')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHdITZUAzQYG"
   },
   "outputs": [],
   "source": [
    "print(\"Waveform: {}\\n\".format(waveform))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(waveform.t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEFLn0DAK4Y4"
   },
   "source": [
    "Escuchamos el espectograma con la librería de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "kLwAcRJ155pl",
    "outputId": "71e85a3f-0319-419a-aa04-fb3cc208a505"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(waveform,rate=samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "vcCdQJS8G-pX",
    "outputId": "98d76ed6-89b5-4992-83fc-b6f9d57c65c4"
   },
   "outputs": [],
   "source": [
    "specgram.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "-dr5Qhgk5sjL",
    "outputId": "dcaafe9a-2223-43e0-c4d6-267dd76a710d"
   },
   "outputs": [],
   "source": [
    "# Fijar la semilla para que la división sea reproducible\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# Calcular tamaños basados en porcentajes\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = int(0.1 * total_size)\n",
    "test_size = total_size - train_size - val_size\n",
    "\n",
    "# Dividir el dataset\n",
    "train_ds, val_ds, test_ds = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Comprobación de los tamaños de cada subconjunto\n",
    "len(train_ds), len(val_ds), len(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "wBHjbBoo5sG1",
    "outputId": "38c86cce-ddd8-4041-82ff-355b97c90397"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 20\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "valid_dl = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
    "test_dl = DataLoader(test_ds,1, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXnHDpoYttX8"
   },
   "source": [
    "### 4. Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "versión más parametrizable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, num_classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        in_size = input_size\n",
    "        for h in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_size, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            in_size = h\n",
    "        layers.append(nn.Linear(in_size, num_classes))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)  # logits sin softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkfBRO910vu3"
   },
   "outputs": [],
   "source": [
    "# dada por ellos:\n",
    "# class MLP(nn.Module):\n",
    "#     def __init__(self, n_input, hidden_dim=64, n_output=10):\n",
    "#         super(MLP, self).__init__()\n",
    "#         # Define layers dynamically\n",
    "#         self.fc1 = nn.Linear(n_input, hidden_dim)  # First hidden layer\n",
    "#         self.fc2 = nn.Linear(hidden_dim, hidden_dim)  # Second hidden layer\n",
    "#         self.fc3 = nn.Linear(hidden_dim, n_output)  # Output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))  # First hidden layer with ReLU\n",
    "#         #x = F.relu(self.fc2(x))  # Second hidden layer with ReLU\n",
    "#         #x = self.fc3(x)          # Output layer, no activation as it's used for logits\n",
    "#         return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "Ryss1Hhm3KUf",
    "outputId": "33618575-44a9-4a2f-eb82-f477f7d0f22e"
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MLP(n_input=110250, n_output=len(classes))\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "n = count_parameters(model)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1729951717955,
     "user": {
      "displayName": "Viviana Siless",
      "userId": "15860013236157608977"
     },
     "user_tz": 180
    },
    "id": "jTnjUZU_3oou",
    "outputId": "8a3e4f17-5425-4e30-dc13-14c724ac6971"
   },
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6cJrYPk8V8J",
    "outputId": "a184e038-e1e1-41bc-a7d4-92c22a46eddd"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
    "valid_losses = []\n",
    "num_epochs = 5\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect() #importante para ir liberando memoria ram\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for wav, genre_index in train_dl:\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        wav=wav.to(device)\n",
    "        genre_index =torch.as_tensor(genre_index).to(device)\n",
    "\n",
    "        # Forward\n",
    "        out = model(wav)\n",
    "        #M5\n",
    "        loss = F.nll_loss(out.squeeze(), genre_index)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        del wav #importante para ir liberando memoria ram\n",
    "        del genre_index #importante para ir liberando memoria ram\n",
    "        del loss #importante para ir liberando memoria ram\n",
    "        del out  #importante para ir liberando memoria ram\n",
    "        torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
    "        gc.collect() #importante para ir liberando memoria ram\n",
    "\n",
    "    print('Epoch: [%d/%d], Train loss: %.4f' % (epoch+1, num_epochs, np.mean(losses)))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    losses = []\n",
    "    correct =0\n",
    "    for wav, genre_index in valid_dl:\n",
    "        #print(wav, genre, index)\n",
    "        wav = wav.to(device)\n",
    "        genre_index = genre_index.to(device)\n",
    "\n",
    "        out = model(wav)\n",
    "\n",
    "        loss = F.nll_loss(out.squeeze() , genre_index)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        #M5\n",
    "        pred= out.argmax(dim=-1).flatten()\n",
    "        # append labels and predictions\n",
    "        correct += pred.eq(genre_index).sum().item()\n",
    "        y_true.extend(genre_index)\n",
    "        y_pred.extend(pred)\n",
    "        del wav #importante para ir liberando memoria ram\n",
    "        del genre_index #importante para ir liberando memoria ram\n",
    "        del loss #importante para ir liberando memoria ram\n",
    "        del out  #importante para ir liberando memoria ram\n",
    "        torch.cuda.empty_cache()  #importante para ir liberando memoria ram\n",
    "        gc.collect() #importante para ir liberando memoria ram\n",
    "\n",
    "    accuracy =correct/ len(valid_dl.dataset)\n",
    "    valid_loss = np.mean(losses)\n",
    "    print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n",
    "\n",
    "    # Save model\n",
    "    valid_losses.append(valid_loss.item())\n",
    "    if np.argmin(valid_losses) == epoch:\n",
    "        print('Saving the best model at %d epochs!' % epoch)\n",
    "        torch.save(model.state_dict(), 'best_model.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFwYdlWxCN0M"
   },
   "source": [
    "\n",
    "\n",
    "### 5. Evaluación\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V6RFD17nU81b"
   },
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_ds,1,shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Pqtx-D0zAwa"
   },
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "S = torch.load('best_model.ckpt')\n",
    "model.load_state_dict(S)\n",
    "print('loaded!')\n",
    "\n",
    "# Run evaluation\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for wav, genre_index in test_dl:\n",
    "        wav = wav.to(device)\n",
    "        genre_index = genre_index.to(device)\n",
    "\n",
    "        out = model(wav)\n",
    "\n",
    "        pred= out.argmax(dim=-1).flatten()\n",
    "        # append labels and predictions\n",
    "        correct += pred.eq(genre_index).sum().item()\n",
    "        y_true.extend(genre_index)\n",
    "        y_pred.extend(pred)\n",
    "\n",
    "accuracy =correct/ len(test_dl.dataset)\n",
    "print('Epoch: [%d/%d], Valid loss: %.4f, Valid accuracy: %.4f' % (epoch+1, num_epochs, valid_loss, accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GA6O4xauAZFH"
   },
   "outputs": [],
   "source": [
    "waveform,label= test_dl.dataset[12]\n",
    "print(\"shape of waveform {}, sample rate with {}, label is {} \".format(waveform.size(),samplerate,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wUg9zOkbAo6-"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "IPython.display.Audio(waveform, rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnqTp_twAtH7"
   },
   "outputs": [],
   "source": [
    "wav= torch.unsqueeze(waveform, dim=0)\n",
    "model.to(device)\n",
    "wav =wav.to(device)\n",
    "out = model(wav)\n",
    "pred= out.argmax(dim=-1).flatten()\n",
    "classes[pred], classes[label]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1uSkwnShxrUa6Ocl0ZCQzQeuwKQWp24Z5",
     "timestamp": 1729951799904
    },
    {
     "file_id": "1lrf3m7jiHExmejRfEvvkQ_-QhvS9yGXB",
     "timestamp": 1699196272732
    },
    {
     "file_id": "1MM5mye38mQC3MsJVPhger99FhS0t8g7u",
     "timestamp": 1699191135065
    },
    {
     "file_id": "1-ubJpQ2KKjHbD0Bw5Vk6hNK1jK4EP8Vr",
     "timestamp": 1699127564522
    }
   ]
  },
  "kernelspec": {
   "display_name": "metodos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
